Lock을 회피하는 프로그래밍
- Data Race를 줄여서 Lock의 필요성 자체를 줄인다.
	. 아무 문제 없다.
	. 효과가 매우 크다.
	. 어렵다.
- Data Race가 있지만 전후 사정을 잘 파악해서 Lock을
  넣지 않아도 잘 수행되도록 프로그래밍 한다.
	. 효과가 있다.
	. 많은 함정들이 있다.
	. Lock의 구현은 이 방법 밖에 없다.

동기화
- 쓰레드끼리 데이터를 주고받거나
- 실행 순서를 맞추는 행위
- 협업을 위해 필수

동기화 구현
- 공유 메모리를 통해 정보를 주고받음
- 당연히 Data Race이니 mutex 필요

뮤텍스는 무거우니까 없이 프로그래밍 해 보자.
1. 컴파일러가 최적화를 한다고 이상하게 컴파일 한다. 
- volatile로 막을 수 있다.
2. CPU가 장난을 친다 (Out of order execution) 다른 코어에서 봤을 때 프로그램 실행 순서가 엉망
- atomic_thread_fence로 막을 수 있다.
3. cache line
4. ABA -> 멀티코어 시간에 다룸


우리의 시도
- 간단한 동기화에 mutex가 필요한가
- volatile을 사용하면 된다
	. 반드시 메모리를 읽고 쓴다.
	. 변수를 레지스터에 할당하지 않는다.
	. 읽고 쓰는 순서를 지킨다.

volatile의 사용법
- volatile int* a;
	. *a = 1
	  최적화로 인한 오동작을 하지 않음
	. a = b
	  컴파일러의 최적화 대상에 포함
- int* volatile a;
	. *a = 1
	  컴파일러의 최적화 대상에 포함
	. a = b
	  최적화로 인한 오동작을 하지 않음

- while (!qnode->next)
	. 위와 같은 코드의 최적화를 막으려면 Qnode* volatile next와 같이
	  선언해야 한다.

피터슨 알고리즘 동기화 메모리 일관성 문제
- CPU는 사기를 친다
	. Out of order execution
	. Write Buffering
- CPU는 프로그램을 순차적으로 실행하는 척만 한다.
	. 싱글코어에서는 절대로 들키지 않는다.
- 이를 메모리 일관성 문제(Memory Consistency Problem)이라고 한다.

write buffering은 cpu가 메모리에 쓸 때 캐시미스가 나서 당장 쓸 수가 없다면
캐시에 내가 쓰고자 하는 주소가 메모리에 올라올때까지 버퍼에 놔두고 cpu대로 일한다.
그리고 버퍼에 올라오면 write한다. write가 딜레이된다.
이 버퍼는 cpu alu와 별개로 동작한다.
메모리에 쓸 내용이 있을 때 캐시에 있으면 쓰고 넘어가면 되는데, 캐시에 없으면
write 버퍼에 넣고 캐시에 올라올때까지 기다렸다가 write버퍼에 있는 내용이
캐시에 들어오는거 기다리지 않고 자기 할일 한다. 독립적으로 실행한다.
그래서 프로그램 실행 속도가 빨라지지만, 이때문에 오동작이 발생한다.

싱글쓰레드에서는 문제가 생기지 않는데 멀티쓰레드에서 문제가 생기는 이유는
write buffering 때문이다. 컴파일러가 프로그램을 기계어로 바꾸고, 프로그램 카운터가
증가하면서 하나하나 실행하는 것처럼 보이는데 그렇게 하지 않는다.
명령어가 있을 때 out of order로 실행 가능한 명령어를 미리 뽑아서 실행하고,
실행 순서대로 저장하는게 아니라 버퍼에 넣는다.
버퍼에 들어간 순서대로 들어간다는 보장이 없다.
캐시가 히트된다면 히트된 것부터 쓰고, 미스된건 기다릴 수 있다.
또, 메모리 쓰고 다른 명령어에서 메모리를 읽어야 하는데 쓰지도 않고 읽는 경우도 있다.
write buffer에만 있고 메모리에는 없는데 메모리를 읽는 것이다.
싱글쓰레드 프로그래밍에서는 이게 들키지 않는다. 메모리를 읽기 전에 write buffer를 검사하여
읽으려는 값이 버퍼에 있다면 그 값을 읽는다.
그런데 멀티코어에서는 이러한 문제가 나타난다. 옆 코어의 write buffer를 볼 수 없기 때문이다
이런 문제를 메모리 일관성 문제라고 한다.

_asm mfence
- intel cpu가 아니면 호환성 문제가 생긴다.
- 64비트 환경에서는 쓸 수 없다.

atomic_thread_fence(std::memory_order_seq_cst)
- 메모리 접근 순서를 강제하는 명령어
- 앞의 명령어들의 메모리 접근이 끝나기 전까지 뒤의
  명령어들의 메모리 접근을 시작하지 못하게 한다.

Out-of-order 실행
a = b*c*d*e;
f = 3;
-> f = 3이 먼저 종료된다.
a = b;	// cache miss
c = d;	// cache hit	
-> c = d가 먼저 종료된다.

문제는 메모리
- 프로그램 순서대로 읽고 쓰지 않는다.
	. volatile로도 해결되지 않는다.
	  - volatile 키워드는 기계어로 번역되지 않는다.
	. 읽기와 쓰기는 시간이 많이 걸리므로
	  - CPU의 입장에서 보면
	  - 실제 메모리 접근 시간은 상대 core에 따라 다르다.
	. 옆의 프로세서(core)에서 보면 뒤바뀐 순서가 보인다.
	  - 자기 자신은 절대 알지 못한다.

부정확해 보이는 결과가 나오는 이유
- 현재의 cpu는 out of order 실행을 한다.
- 메모리의 접근은 순간적이 아니다.
- 멀티코어에서는 옆 코어의 out of order 실행이 관측된다.


- 메모리 일관성 테스트 2
캐시 메모리는 데이터와 태그로 분류된다.
한 바이트마다 64비트짜리 태그가 붙으면 낭비가 장난이 아니므로
캐시는 64바이트 라인 단위로 관리된다. (성능 상으로도 이득이 있다. -> 데이터의 지역성)
캐시는 한 번에 64바이트를 한 번에 읽기 때문에 시간상으로 차이도 없다.
bound가 cache line 두 라인에 걸쳐 있으면 데이터를 읽고/쓰기 위해
2번 접근해야 한다. 이는 명백히 원자적이지 않다.

- 중간값
	. write 시 최종값과 초기값이 아닌 다른 값이 도중에 메모리에 써지는 현상
	. read 도중 다른 쓰레드가 값을 변경
- 이유는?
	. cache line size boundary
	. 확인 : -2를 -1, -3, -4로 교체
- 대책은?
	. Byte밖에 믿을 수 없다.
	. Pointer가 아닌 '변수'는 Visual C++가 알아서 잘 해준다.
	  (int를 선언 한다면 모든 int 변수는 주소가 4의 배수이다. 
	  4의 배수면 절대 Cache Line Boundary에 걸치지 않는다.)
	. Pointer를 절대 믿지 마라.
	. #pragma pack을 조심하라
	  하는 순간 4의 배수 규칙이 깨진다.

. PC에서의 공유 메모리
- 다른 코어에서 보았을 때 업데이트 순서가 다를 수 있다.
- 메모리의 내용이 한 순간에 업데이트 되지 않을 때도 있다.

. 그래도 희망적
- 언젠가는 메모리에 대한 쓰기가 실행 된다.
- 자기 자신의 프로그램 순서는 지켜진다. (내가 봤을 때는 문제 없다.)
- 캐시의 일관성은 지켜진다.
	. 한번 지워졌던 값이 다시 살아나지는 않는다.
	. 언젠가는 모든 코어가 동일한 값을 본다.
- 캐시라인 내부의 쓰기는 중간값(원자적이지 않은)을 만들지 않는다.

해결책
- 이러한 상황을 고려하면서 프로그래밍을 한다.
	. 가능하지만 프로그래밍이 너무 어려워진다.
- lock을 넣어서 순서의 어긋남을 제거한다.
	. 프로그램이 너무 느려진다.
	. lock()의 구현은?
- 문제가 되는 부분 어긋남을 제거한다.
	. atomic_thread_fence 사용
	. 어렵다. 남발 시 성능 저하
- 기존의 멀티쓰레드용 라이브러리를 사용한다.
	. C++11 <atomic>

메모리 일관성 문제를 없애는 법
- Atomic template 사용

Atomic
- 접근(read, write)의 절대 순서가 모든 쓰레드에서 지켜지는 메모리
- 대부분의 멀티쓰레드 알고리즘이 atomic 메모리를 바탕으로 한다.
- 싱글코어에서는 atomic template 없이도 atomic하게 동작한다.
- mutex보단 빠르다. 그러나 오버헤드가 있다. (싱글쓰레드가 빠른 경우도 있다.)

atomic한 int를 만들 수 있는가?
- SW적으로 구현할 수 있다.
	. 대학원 과정
	. 복잡, 고비용
- HW적으로 구현되어 있다.
	. CPU에 특수 명령어로 구현되어 있다.
	. C++11의 atomic<> 템플릿을 사용해도 된다.

atomic 자료 구조
- Atomic memory를 사용하여 자료구조를 만들면 atomic한가?
	. NO
	. 예) sum = sum + 2;
효율적인 atomic 자료구조가 필요하다.
- lock으로 atomic 자료구조를 만들면
	. 병렬성이 떨어진다.
	. 너무 느리다
atomic operation 2개 모아뒀다고 저절로 합체돼서 하나의 atomic operation이 되는 것이 아니다.
	

효율적인 멀티쓰레드 자료구조의 구현
- Lock없는 구현
	. 성능 저하의 주범이므로 당연
- Lock이 없다고 성능저하가 없는가?
	. 상대방 쓰레드에서 어떤 일을 해주기를 기다리고 있다면
	  동시실행으로 인한 성능 개선을 얻기 힘들다.
	. 상대방 쓰레드의 행동에 의존적이지 않은 구현이 필요하다.

blocking
- 다른 쓰레드의 진행 상태에 따라 진행이 막힐 수 있음.
	. while (lock != 0)
- 멀티쓰레드의 bottle neck이 생긴다.
- lock을 사용하면 blocking
문제점
- 성능저하: lock 오버헤드, 병렬성 저하
- Priority Inversion
	. Lock을 공유하는 덜 중요한 작업들이 중요한 작업의 실행을 막는 현상
	  ex) Inqueue가 dequeue보다 더 중요한데, lock으로 막고 있다.
- Convoying
	. lock을 얻을 쓰레드가 스케줄링에서 제외된 경우, lock을
	  기다리는 모든 쓰레드가 공회전
	. Core보다 많은 수의 thread를 생성했을 경우 자주 발생

non-blocking
- 다른 쓰레드가 어떠한 삽질을 하고 있던 상관없이 진행
	예) 공유메모리 읽기/쓰기, atomic<int>에서 '+='
- 여러 개의 method를 갖고 있는 class이다.
- 여러 쓰레드에서 동시에 method를 호출해도 오류 없이 동작한다.
- 다른 쓰레드에서 동시에 method를 호출했다고 해서 속도가 느려지지 않는다. (wait-free)
	. 속도가 좀 느려질 수 있지만, 어느 쓰레드가 멈추었다고 해서
	  다른 쓰레드가 멈추는 경우는 절대 없다. (lock-free)
등급
- 무대기 (wait-free)
	. 모든 메소드가 정해진 유한한 단계에 실행을 끝마침
	. 멈춤 없는 프로그램 실행
- 무잠금 (lock-free)
	. 항상, 적어도 한 개의 메소드가 유한한 단계에 실행을 끝마침
	. 무대기이면 무잠금이다.
	. 기아(starvation)을 유발하기도 한다.
	  모든 쓰레드가 starvation에 걸리지는 않는다.
	  애초에 걸릴 확률이 매우 낮다.
	. 성능을 위해 무대기 대신 무잠금을 선택하기도 한다.

- Wait free, lock free
	. lock을 사용하지 않고
	. 다른 쓰레드가 어떠한 행동을 하기를 기다리는 것
	. 자료구조의 접근을 atomic하게 해주는 알고리즘의 등급
- 멀티쓰레드 프로그램에서 쓰레드 사이의
  효율적인 자료 교환과 협업을 위해서는 Non-blocking 자료 구조가 필요하다.

atomic memory로 non-blocking 자료구조를 만들 수 있는가?
- queue, map, stack...
->아니다.
- 공유 메모리를 읽고 쓰면서 동기화하는 방식으로는
  Non-blocking 자료구조를 구현할 수 없다.
-> atomic memory만으로는 다중 쓰레드 무대기 큐를 만들 수 없다.

- 내가 메모리에 할 수 있는 작업 -> Read, Write (Clear 이런 거 없음)
다중 쓰레드 무대기 큐를 만들려면?
- CAS (Compare And Set) 연산이 필요하다.
- 기존의 공유메모리는 Read와 Write 연산만 있었다.

CAS
- Compare And Set
- 메모리에 어떤 값을 쓰는데 원래 있던 값하고 비교한다.
  비교해서 같으면 쓰고, 다르면 쓰지 않는다.
- Atomic하고, Wait-Free 하게 동작한다.
- Read, Write만으로는 절대 만들 수 없다,
	. 하드웨어의 도움이 필요하다.

- MEM.CAS(A, B)
	. MEM의 값이 A면 MEM의 값을 B로 바꾸고 true를 리턴
	. MEM의 값이 A가 아니면 아무것도 하지 않고 false를 리턴
	  간단하게 구현 가능한 거 아님? -> 그렇긴 한데 atomic하지 않음
	  프로그래밍으로 구현할 수 없고(증명됨) 하드웨어 단에서 구현되어야 함

atomic_compare_exchange_strong

CAS로 Lock 구현
- 0으로 초기화되어있는 공유 메모리 x가 있을 때, 모든 쓰레드에서
  CAS(&X, 0, 1)
  를 실행 시키면 오직 하나의 쓰레드만 X가 0이 되면서 true를 리턴한다.
- CAS는 atomic하게 실행되므로 여러 쓰레드가 실행해도 반드시 한 쓰레드만 실행된다.

멀티쓰레드에서 속도가 떨어진다.
루프를 돌면서 CAS를 하는 오버헤드 때문에 전체적인 컴퓨터 성능이 떨어진다.
convoying 때문에 lock을 얻고 스케줄아웃 당한다.
시분할 운영체제이니까 다른 쓰레드들이 lock을 얻지 못하고 헛돌게 된다.
쓰레드가 많아질수록 lock을 얻은 채로 running에서 ready로 떨어질 확률이 크다.
그래서 점점 더 성능이 느려진다.

왜 쓰느냐
- 기존의 '모든' 자료구조를 멀티쓰레드 wait-free 자료구조로 변환할 수 있다.
- 간단한 변환 알고리즘이 존재한다.
	. 존재하지만 너무 비효율적이다.
	. 100배 이상의 성능 저하가 일어난다.
- 각각의 자료구조에 맞추어 최적화를 해야한다.
	. 최적화는 힘들지만, 고성능이 가능하다.
	. 한다면 mutex보다 빠르다.
- 이미 최적화 되어있는 라이브러리를 쓰는 것이 좋다.
	. visual studio 2010 : PPL
	. Intel : TBB

재정의
고성능 멀티 쓰레드 프로그래밍
- 비멈춤(non-blocking) 자료구조를 사용한 프로그래밍
- lock은 사용하지 않지만 CAS는 필요하다.
  (CAS 없이는 만들 수 없음이 증명되어 있다.)


정리
- 멀티 쓰레드 프로그래밍에서는 공유 메모리를 사용해서 쓰레드간 협업을 한다.
- Data Race로 인한 잘못된 결과
	. Data Race를 없애는 것은 lock()이 기본
- lock()으로 인한 심각한 성능 저하
- lock()을 제거
	. 직접 공유메모리를 사용했을 때 생기는 문제
	  컴파일러, 일관성, 중간값
- atomic한 공유 자료 구조를 만들어서 사용해야 한다.
	. non-blocking 자료구조가 바람직하다.
- 좋은 공유 자료 구조는 만들기 힘들다
	. 무대기(wait free) 알고리즘의 작성은 까다롭다.
	. 상용 라이브러리도 좋다. (TBB, PPL)