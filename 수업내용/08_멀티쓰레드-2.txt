Lock을 회피하는 프로그래밍
- Data Race를 줄여서 Lock의 필요성 자체를 줄인다.
	. 아무 문제 없다.
	. 효과가 매우 크다.
	. 어렵다.
- Data Race가 있지만 전후 사정을 잘 파악해서 Lock을
  넣지 않아도 잘 수행되도록 프로그래밍 한다.
	. 효과가 있다.
	. 많은 함정들이 있다.
	. Lock의 구현은 이 방법 밖에 없다.

동기화
- 쓰레드끼리 데이터를 주고받거나
- 실행 순서를 맞추는 행위
- 협업을 위해 필수

동기화 구현
- 공유 메모리를 통해 정보를 주고받음
- 당연히 Data Race이니 mutex 필요

우리의 시도
- 간단한 동기화에 mutex가 필요한가
- volatile을 사용하면 된다
	. 반드시 메모리를 읽고 쓴다.
	. 변수를 레지스터에 할당하지 않는다.
	. 읽고 쓰는 순서를 지킨다.

volatile의 사용법
- volatile int* a;
	. *a = 1
	  최적화로 인한 오동작을 하지 않음
	. a = b
	  컴파일러의 최적화 대상에 포함
- int* volatile a;
	. *a = 1
	  컴파일러의 최적화 대상에 포함
	. a = b
	  최적화로 인한 오동작을 하지 않음

- while (!qnode->next)
	. 위와 같은 코드의 최적화를 막으려면 Qnode* volatile next와 같이
	  선언해야 한다.

피터슨 알고리즘 동기화 메모리 일관성 문제
- CPU는 사기를 친다
	. Out of order execution
	. Write Buffering
- CPU는 프로그램을 순차적으로 실행하는 척만 한다.
	. 싱글코어에서는 절대로 들키지 않는다.
- 이를 메모리 일관성 문제(Memory Consistency Problem)이라고 한다.

write buffering은 cpu가 메모리에 쓸 때 캐시미스가 나서 당장 쓸 수가 없다면
캐시에 내가 쓰고자 하는 주소가 메모리에 올라올때까지 버퍼에 놔두고 cpu대로 일한다.
그리고 버퍼에 올라오면 write한다. write가 딜레이된다.
이 버퍼는 cpu alu와 별개로 동작한다.
메모리에 쓸 내용이 있을 때 캐시에 있으면 쓰고 넘어가면 되는데, 캐시에 없으면
write 버퍼에 넣고 캐시에 올라올때까지 기다렸다가 write버퍼에 있는 내용이
캐시에 들어오는거 기다리지 않고 자기 할일 한다. 독립적으로 실행한다.
그래서 프로그램 실행 속도가 빨라지지만, 이때문에 오동작이 발생한다.

atomic_thread_fence(std::memory_order_seq_cst)
- 메모리 접근 순서를 강제하는 명령어
- 앞의 명령어들의 메모리 접근이 끝나기 전까지 뒤의
  명령어들의 메모리 접근을 시작하지 못하게 한다.

Out-of-order 실행
a = b*c*d*e;
f = 3; // f = 3이 먼저 종료된다.
a = b;	// cache miss
c = d;	// cache hit	c = d가 먼저 종료된다.

문제는 메모리
- 프로그램 순서대로 읽고 쓰지 않는다.
	. volatile로도 해결되지 않는다.
	  - volatile 키워드는 기계어로 번역되지 않는다.
	. 읽기와 쓰기는 시간이 많이 걸리므로
	  - CPU의 입장에서 보면
	  - 실제 메모리 접근 시간은 상대 core에 따라 다르다.
	. 옆의 프로세서(core)에서 보면 뒤바뀐 순서가 보인다.
	  - 자기 자신은 절대 알지 못한다.


- mutex
뮤텍스는 무거우니까 없이 프로그래밍 해 보자.
1. 컴파일러가 최적화를 한다고 이상하게 컴파일 한다. 
- volatile로 막을 수 있다.
2. CPU가 장난을 친다 (Out of order execution) 다른 코어에서 봤을 때 프로그램 실행 순서가 엉망
- atomic_thread_fence로 막을 수 있다.
3. cache line
4. ABA -> 멀티코어 시간에 다룸

메모리 일관성
. 아래의 두 실행 결과는 서로 다르다. 어떠한 것이 정확한 결과인가
-> 둘 다 맞다.
. 그러면 이것은?
-> Out of order execution에선 일어날 수 있다.


- 메모리 일관성 테스트 2
캐시 메모리는 데이터와 태그로 분류된다.
한 바이트마다 64비트짜리 태그가 붙으면 낭비가 장난이 아니므로
캐시는 64바이트 라인 단위로 관리된다. (성능 상으로도 이득이 있다. -> 데이터의 지역성)
캐시는 한 번에 64바이트를 한 번에 읽기 때문에 시간상으로 차이도 없다.
bound가 cache line 두 라인에 걸쳐 있으면 데이터를 읽고/쓰기 위해
2번 접근해야 한다. 이는 명백히 원자적이지 않다.

- 대책은?
. Byte밖에 믿을 수 없다.
. Pointer가 아닌 '변수'는 Visual C++가 알아서 잘 해준다.
(int를 선언 한다면 모든 int 변수는 주소가 4의 배수이다. 
4의 배수면 절대 Cache Line Boundary에 걸치지 않는다.)
. Pointer를 절대 믿지 마라.
. #pragma pack을 조심하라
	하는 순간 4의 배수 규칙이 깨진다.

. PC에서의 공유 메모리
- 다른 코어에서 보았을 때 업데이트 순서가 다를 수 있다.
- 메모리의 내용이 한 순간에 업데이트 되지 않을 때도 있다.

. 그래도 희망적
- 언젠가는 메모리에 대한 쓰기가 실행 된다.
- 자기 자신의 프로그램 순서는 지켜진다. (내가 봤을 때는 문제 없다.)
- 캐시의 일관성은 지켜진다.
	. 한번 지워졌던 값이 다시 살아나지는 않는다.
	. 언젠가는 모든 코어가 동일한 값을 본다.
- 캐시라인 내부의 쓰기는 중간값(원자적이지 않은)을 만들지 않는다.


atomic
메모리 일관성 문제를 없애는 법
- Atomic template 사용

Atomic
- 접근(read, write)의 절대 순서가 모든 쓰레드에서 지켜지는 메모리
- 대부분의 멀티쓰레드 알고리즘이 atomic 메모리를 바탕으로 한다.
- 싱글코어에서는 atomic template 없이도 atomic하게 동작한다.
- mutex보단 빠르다. 그러나 오버헤드가 있다. (싱글쓰레드가 빠른 경우도 있다.)


효율적인 멀티쓰레드 자료구조의 구현
- Lock없는 구현
- Lock이 없다고 성능저하가 없는가?
	. 상대방 쓰레드에서 어떤 일을 해주기를 기다리고 있다면
	  동시실행으로 인한 성능 개선을 얻기 힘들다.

blocking
- 다른 쓰레드의 진행 상태에 따라 진행이 막힐 수 있음.
- 멀티쓰레드의 bottle neck이 생긴다.
- lock을 사용하면 blocking
문제점
- 성능저하: lock 오버헤드, 병렬성 저하
- Priority Inversion
	. Lock을 공유하는 덜 중요한 작업들이 중요한 작업의 실행을 막는 현상
	  ex) Inqueue가 dequeue보다 더 중요한데, lock으로 막고 있다.
- Convoying
	. lock을 얻을 쓰레드가 스케줄링에서 제외된 경우, lock을
	  기다리는 모든 쓰레드가 공회전
	. Core보다 많은 수의 thread를 생성했을 경우 자주 발생

non-blocking
- 다른 쓰레드가 어떠한 삽질을 하고 있던 상관없이 진행
	예) 공유메모리 읽기/쓰기, atomic<int>에서 '+='
- 여러 개의 method를 갖고 있는 class이다.
- 여러 쓰레드에서 동시에 method를 호출해도 오류 없이 동작한다.
- 다른 쓰레드에서 동시에 method를 호출했다고 해서 속도가 느려지지 않는다. (wait-free)
	. 속도가 좀 느려질 수 있지만, 어느 쓰레드가 멈추었다고 해서
	  다른 쓰레드가 멈추는 경우는 절대 없다. (lock-free)
등급
- 무대기 (wait-free)
	. 모든 메소드가 정해진 유한한 단계에 실행을 끝마침
	. 멈춤 없는 프로그램 실행
- 무잠금 (lock-free)
	. 항상, 적어도 한 개의 메소드가 유한한 단계에 실행을 끝마침
	. 무대기이면 무잠금이다.
	. 기아(starvation)을 유발하기도 한다.
	  모든 쓰레드가 starvation에 걸리지는 않는다.
	  애초에 걸릴 확률이 매우 낮다.
	. 성능을 위해 무대기 대신 무잠금을 선택하기도 한다.

Wait free, lock free
	. lock을 사용하지 않고
	. 다른 쓰레드가 어떠한 행동을 하기를 기다리는 것
	. 자료구조의 접근을 atomic하게 해주는 알고리즘의 등급


- 공유 메모리를 읽고 쓰면서 동기화하는 방식으로는
  Non-blocking 자료구조를 구현할 수 없다.
- 내가 메모리에 할 수 있는 작업 -> Read, Write (Clear 이런 거 없음)
- CAS (Compare And Set) 연산이 필요하다.
CAS
- 메모리에 어떤 값을 쓰는데 원래 있던 값하고 비교한다.
  비교해서 같으면 쓰고, 다르면 쓰지 않는다.
- Atomic하고, Wait-Free 하게 도앚ㄱ한다.
- Read, Write만으로는 절대 만들 수 없다,
	. 하드웨어의 도움이 필요하다.

- MEM.CAS(A, B)
	. MEM의 값이 A면 MEM의 값을 B로 바꾸고 true를 리턴
	. MEM의 값이 A가 아니면 아무것도 하지 않고 false를 리턴
	  간단하게 구현 가능한 거 아님? -> 그렇긴 한데 atomic하지 않음
	  프로그래밍으로 구현할 수 없고(증명됨) 하드웨어 단에서 구현되어야 함

atomic_compare_exchange_strong

CAS로 Lock 구현
- 0으로 초기화되어있는 공유 메모리 x가 있을 때, 모든 쓰레드에서
	CAS(&X, 0, 1)
- 를 실행 시키면 오직 하나의 쓰레드만 X가 0이 되면서 true를 리턴한다.
- CAS는 atomic하게 실행되므로 여러 쓰레드가 실행해도 반드시 한 쓰레드만 실행된다.


왜 쓰느냐
- 기존의 '모든' 자료구조를 멀티쓰레드 wait-free 자료구조로 변환할 수 있다.
- 간단한 변환 알고리즘이 존재한다.
	. 존재하지만 너무 비효율적이다.
	. 100배 이상의 성능 저하가 일어난다.
- 각각의 자료구조에 맞추어 최적화를 해야한다.
	. 최적화는 힘들지만, 고성능이 가능하다.
	. 한다면 mutex보다 빠르다.
- 이미 최적화 되어있는 라이브러리를 쓰는 것이 좋다.